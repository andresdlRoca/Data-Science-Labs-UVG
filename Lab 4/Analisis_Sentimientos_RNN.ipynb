{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO4Yvxr1PbBT"
   },
   "source": [
    "## Análisis de Sentimientos de críticas de películas\n",
    "\n",
    "Junto con Keras, viene un ejemplo imdb_lstm.py. Este ejercicio esta prácticamente basado en él.\n",
    "\n",
    "Es un gran ejemplo del uso de las RNNs.  El conjunto de datos que se utilizará consta de críticas de películas generadas por usuarios, y una classificación indicando si le gustó, o no, basado en su rating asociado. \n",
    "\n",
    "Hay más información de este conjunto de datos en:\n",
    "\n",
    "https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
    "\n",
    "Como la comprensión del lenguaje escrito requiere \"llevar cuenta\" de todas las palabras en una oración, necesitamos una RNN para mantener una \"memoria\" de las palabras que pasaron antes, conforme va \"leyendo\" oraciones a lo largo del tiempo. \n",
    "\n",
    "En particular, se usarán unidades LSTM (Long Short-Term Memory) porque no es deseable \"olvidar\" palabras demasiado rápido...las palabras al inicio de una oración pueden afectar el significado de la misma grandemente.\n",
    "\n",
    "Empezamos por la importación de lo que se requiere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-5GymP2ePbBc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aFJnFb7PbBd"
   },
   "source": [
    "Ahora importar los datos para entrenamiento y prueba.  Para que sea más manejable, se especifica que se quieren solamente las 20,000 palabras más populares en el conjunto de datos. Por algún motivo, este conjunto tiene una relación de 50% entreno y 50% prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThMIo9DYPbBd",
    "outputId": "0dbe0c33-c2b7-427c-e4ac-fc97e80cee85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando los datos...\n"
     ]
    }
   ],
   "source": [
    "print('Cargando los datos...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_EZvv_6PbBd"
   },
   "source": [
    "A ver cómo son los datos, el primer elemento de entrenamiento debe ser una crítica de una película:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPsneaWNPbBe",
    "outputId": "cc84e444-4b55-4a9f-f3db-068d91ec85c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 22665,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 21631,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 31050,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoHWVuCEPbBe"
   },
   "source": [
    "Esto no parece una crítica de una película!!!!  Resulta que la gente que preparó los datos ya hicieron algo de preparación previa de los datos.  Estos números coinciden con el índice correspondiente a cada palabra de la crítica.  En realidad las palabras en sí, no son de interés...el modelo requiere números no palabras. \n",
    "\n",
    "Lo triste es que no será posible leer las críticas...siquiera para tener una idea de si funciona el análiisis, o no.\n",
    "\n",
    "Y, ¿cómo son las etiquetas (metas)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxKy_iFPPbBe",
    "outputId": "7fd0922e-9098-4b26-c8d2-078a296c1074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPLmsWk5PbBe"
   },
   "source": [
    "Son simplemente 0 ó 1, que indica sí al que escribió la crítica le gustó, o no, la película.\n",
    "\n",
    "Para resumir, para el entrenamiento se tiene un conjunto de críticas de películas que han sido convertidas a vectores de palabras representadas por enteros, y una clasificación de sentimiento binaria.\n",
    "\n",
    "Las RNNs pueden \"explotar\"\"\n",
    " (se habló de esto en clase) muy rápidamente.  Para que no se sobrecarguen las PCs que se podrían usar, se limitarán las críticas a las primeras 80 palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "td7nNbGcPbBf"
   },
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen = 80)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUFGeOFOPbBf"
   },
   "source": [
    "## Configuración del modelo\n",
    "\n",
    "Considerando lo complejo que es una RNN LSTM (debajo del \"capó\"), es increíble lo simple que resulta esta parte utilizando Keras.\n",
    "\n",
    "Se empieza con una capa de incrustación \"embedded\".  La función de esta es convertir los datos de entrada a vectores densos de un tamaño fijo que son más adecuados para una red neuronal.  Esto es típico cuando se manejan indices de datos basados en texto.  El 20,000 representa el tamaño del vocabulario (límite impuesto para este ejercicio, pero puede variarse dependiendo de la capacidad de cómputo que se tiene) y 128 es la dimensión de 128 unidades de salida.\n",
    "\n",
    "Luego se coloca una capa LSTM y ya!  Se especifica 128 para igualar la salida de la capa de incrustación, y se utiliza la opción de \"botar\" unidades para evitar el sobre ajuste, que es una característica muy común de las RNN.\n",
    "\n",
    "Finalmente se debe reducir todo a una unidad de salida con una función de activación sigmoidal para seleccionar la clasificación binaria de sentimiento de 0 ó 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "TrgEmhr2PbBf"
   },
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Embedding(50000, 128))\n",
    "modelo.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "modelo.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1bd9f8FPbBg"
   },
   "source": [
    "Ya que este es un problema de clasificación binaria, la mejor función de pérdida es la \"binary_crossentropy\".  También se utiliza el optimizador \"Adam\" que es uno de los mejores.  Siempre es de recordar que si es necesario afinar más el modelo, se pueden probar otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "RGjVEFQxPbBg"
   },
   "outputs": [],
   "source": [
    "modelo.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gWoZ4vUPbBg"
   },
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Las RNNs, al igual que las CNNs son bastante pesadas en el uso de recursos.  Para poder utilizar una PC normal, el mantener el tamaño de las tandas pequeño, es clave.  En un mundo más profesional, se estaría sacando ventaja de GPUs instaladas en un cluster de computadoras para tener un mejor rendimiento.\n",
    "\n",
    "## Advertencia\n",
    "\n",
    "Esto puede tardarse bastante tiempo, aún en una PC potente!  A menos que se quiera ver todo el proceso y esperar una o más horas, no ejecute las siguientes celdas de código.\n",
    "\n",
    "Esta siguiente celda es solo para quienes estén utilizando tensorflow-gpu con Windows.  Sirve para evitar problemas de asignación de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "FwA5wk8iPbBg",
    "outputId": "ff2825e2-c524-4cdf-d8ca-1a91fa6a46d6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # hacer que la memoria usada del GPU crezca dinamicamente \n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "set_session(sess)  # hacer que esta sesión de TensorFlow sea la sesión default de Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdqGjhaiPbBh"
   },
   "source": [
    "Ahora sí, a iniciar el entrenamiento.  Aún con una GPU se tardará bastante tiempo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIqVu_VEPbBh",
    "outputId": "31808fcc-3698-4863-e3dc-c4ddfb080be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 108s - loss: 0.4241 - accuracy: 0.7995 - val_loss: 0.3660 - val_accuracy: 0.8334 - 108s/epoch - 139ms/step\n",
      "Epoch 2/15\n",
      "782/782 - 115s - loss: 0.2308 - accuracy: 0.9104 - val_loss: 0.4160 - val_accuracy: 0.8304 - 115s/epoch - 147ms/step\n",
      "Epoch 3/15\n",
      "782/782 - 111s - loss: 0.1291 - accuracy: 0.9516 - val_loss: 0.5280 - val_accuracy: 0.8080 - 111s/epoch - 142ms/step\n",
      "Epoch 4/15\n",
      "782/782 - 103s - loss: 0.0749 - accuracy: 0.9744 - val_loss: 0.5526 - val_accuracy: 0.8172 - 103s/epoch - 131ms/step\n",
      "Epoch 5/15\n",
      "782/782 - 136s - loss: 0.0511 - accuracy: 0.9824 - val_loss: 0.7497 - val_accuracy: 0.8071 - 136s/epoch - 173ms/step\n",
      "Epoch 6/15\n",
      "782/782 - 151s - loss: 0.0388 - accuracy: 0.9866 - val_loss: 0.8700 - val_accuracy: 0.8088 - 151s/epoch - 193ms/step\n",
      "Epoch 7/15\n",
      "782/782 - 153s - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.7923 - val_accuracy: 0.8170 - 153s/epoch - 195ms/step\n",
      "Epoch 8/15\n",
      "782/782 - 145s - loss: 0.0177 - accuracy: 0.9940 - val_loss: 1.0514 - val_accuracy: 0.8128 - 145s/epoch - 186ms/step\n",
      "Epoch 9/15\n",
      "782/782 - 97s - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.9987 - val_accuracy: 0.8033 - 97s/epoch - 124ms/step\n",
      "Epoch 10/15\n",
      "782/782 - 120s - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.9944 - val_accuracy: 0.8106 - 120s/epoch - 153ms/step\n",
      "Epoch 11/15\n",
      "782/782 - 119s - loss: 0.0150 - accuracy: 0.9955 - val_loss: 1.1190 - val_accuracy: 0.8058 - 119s/epoch - 152ms/step\n",
      "Epoch 12/15\n",
      "782/782 - 107s - loss: 0.0061 - accuracy: 0.9975 - val_loss: 1.1045 - val_accuracy: 0.8105 - 107s/epoch - 137ms/step\n",
      "Epoch 13/15\n",
      "782/782 - 123s - loss: 0.0121 - accuracy: 0.9962 - val_loss: 1.0810 - val_accuracy: 0.8102 - 123s/epoch - 157ms/step\n",
      "Epoch 14/15\n",
      "782/782 - 128s - loss: 0.0052 - accuracy: 0.9984 - val_loss: 1.1592 - val_accuracy: 0.8042 - 128s/epoch - 163ms/step\n",
      "Epoch 15/15\n",
      "782/782 - 127s - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.2683 - val_accuracy: 0.7986 - 127s/epoch - 163ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1916a858640>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(X_train, y_train,\n",
    "          batch_size = 32,\n",
    "          epochs = 15,\n",
    "          verbose = 2,\n",
    "          validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njb4BIEyPbBh"
   },
   "source": [
    "OK, ahora a evaluar la exactitud del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLehygHpPbBi",
    "outputId": "22f98634-7fa3-4c1c-f709-9247286572dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 14s - loss: 1.2683 - accuracy: 0.7986 - 14s/epoch - 18ms/step\n",
      "Pérdida de la Prueba: 1.2682605981826782\n",
      "Exactitud de la Prueba (Test accuracy): 0.7986000180244446\n"
     ]
    }
   ],
   "source": [
    "perdida, exactitud = modelo.evaluate(X_test, y_test,\n",
    "                            batch_size = 32,\n",
    "                            verbose = 2)\n",
    "print('Pérdida de la Prueba:', perdida)\n",
    "print('Exactitud de la Prueba (Test accuracy):', exactitud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-nY4JR8PbBi"
   },
   "source": [
    "Cerca del 80%, no está mal considerando que se limitó el ejercicio a las primeras 80 palabras de cada crítica.\n",
    "\n",
    "Por otro lado - hay que pensar en lo que se hizo en este ejercicio!  Una red neuronal que puede leer críticas y deducir si al autor le gustó la película o no, basado en el texto.  Y el modelo toma en cuenta el contexto y la posición de cada palabra.\n",
    "\n",
    "Lo mejor de todo es que armar el modelo solamente requirió de algunas líneas de código!  Es increíble lo que se puede hacer con Keras!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "8ip7E_-UPbBi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andrès DLR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "modelo.save(\"Anal_Sentimiento.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBG9S2-JPbBi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2q_b2vPFIMs"
   },
   "source": [
    "### Ver algo de las críticas\n",
    "\n",
    "Del enlace provisto arriba, se obtuvo el siguiente código que permite ver el texto del primero de los comentarios.  No sería dificil verlos todos si se quisiera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8vKFX_NPbBi",
    "outputId": "aa31d3ba-3867-4e5c-e1d6-431931d38d37"
   },
   "outputs": [],
   "source": [
    "# Use the default parameters to keras.datasets.imdb.load_data\n",
    "start_char = 1\n",
    "oov_char = 2\n",
    "index_from = 3\n",
    "# Retrieve the training sequences.\n",
    "(X_train, _), _ = tf.keras.datasets.imdb.load_data(\n",
    "    start_char=start_char, oov_char=oov_char, index_from=index_from\n",
    ")\n",
    "# Retrieve the word index file mapping words to indices\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "# And add `index_from` to indices to sync with `x_train`\n",
    "inverted_word_index = dict(\n",
    "    (i + index_from, word) for (word, i) in word_index.items()\n",
    ")\n",
    "# Update `inverted_word_index` to include `start_char` and `oov_char`\n",
    "inverted_word_index[start_char] = \"[START]\"\n",
    "inverted_word_index[oov_char] = \"[OOV]\"\n",
    "# Decode the first sequence in the dataset\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "2M7XZKKTgkDs",
    "outputId": "2f1ab304-da22-40c2-e731-942fdd0cb905"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[START] this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PXwh2Tbgos7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
